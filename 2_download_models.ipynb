{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Download models\n",
    "\n",
    "**TL;DR**: In the first line of code, see that `model_name=\"EleutherAI/gpt-neo-1.3B\"`, and run this code by selecting *Kernel > Restart Kernel and Run All Cells...* in the menu bar at the top left of the screen. You will see the words \"Downloads complete!!\" at the bottom of the page when the models are finished downloading. Then, move on to step 3.\n",
    "\n",
    "**Note: This step takes time. Expect to keep your computer on for at least 30 minutes while the downloads take place.**\n",
    "\n",
    "**Note: You only need to complete this step one time. Once you have the two *model...* folders inside your *internal* folder, the models are downloaded and can be used by steps 3 and 4 as many times as needed to generate content.**\n",
    "\n",
    "The first step in generating the content is to download the natural language processing models that will help produce the content. This program uses two models: GPT-Neo for generating text and a \"zero-shot-classification\" model for determining meaning of text, which is used in finding keywords for post images. \n",
    "\n",
    "## Pick a GPT-Neo model\n",
    "\n",
    "First, decide which GPT-Neo model to use. There are three versions: 125M, 1.3B, and 2.7B. These numbers refer to the number of data parameters used in each - the higher the number, the better the results. For our purposes, **the 1.3B model (~5GB) should suffice**. The 125M may not produce good results, and the 2.7B model (~10GB) will take a while to download (possibly over an hour, depending on internet speed) but would give the best results.\n",
    "\n",
    "To pick a GPT-Neo model, replace the `model_name` parameter with the name of your desired model. For example, if you want to use the 1.3B model, **make sure it reads** `model_name=\"EleutherAI/gpt-neo-1.3B\"`. \n",
    "\n",
    "## Run the program\n",
    "\n",
    "Once you have selected your model, run the program by selecting *Kernel > Restart Kernel and Run All Cells...* in the menu bar at the top left of the screen. You will see the words, \"Downloads complete!!\" at the bottom of the page when the models are finished downloading. Then, move on to step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from happytransformer import HappyGeneration\n",
    "\n",
    "#                                                           ******** HERE ********\n",
    "gpt_neo = HappyGeneration(model_type=\"GPT-NEO\", model_name=\"EleutherAI/gpt-neo-1.3B\") \n",
    "#                                                           ^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# to use an different-sized model, replace the model_name with\n",
    "# \"EleutherAI/gpt-neo-125M\" or \"EleutherAI/gpt-neo-1.3B\" or \"EleutherAI/gpt-neo-2.7B\"\n",
    "\n",
    "gpt_neo.save(\"internal/model_gpt_neo/\")\n",
    "\n",
    "print (gpt_neo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't worry, this second one doesn't take nearly as long to download.\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier.save_pretrained('internal/model_classifier')\n",
    "print(\"\\n\\nDownloads complete!!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
